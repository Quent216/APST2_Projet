{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d70632-9bb6-4b18-a9db-c410aa5fff51",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2 : REINFORCE algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c85378ca-f7e0-488f-af32-8b3cefbb4dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pygame\n",
    "import scipy as sc\n",
    "from collections import deque\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44da1d4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Description\n",
    "\n",
    "The system consists of two links connected linearly to form a chain, with one end of the chain fixed. The joint between the two links is actuated. The goal is to apply torques on the actuated joint to swing the free end of the linear chain above a given height while starting from the initial state of hanging downwards.\n",
    "\n",
    "## Action Space\n",
    "The action is discrete, deterministic, and represents the torque applied on the actuated joint between the two links.\n",
    "    | Num | Action                                | Unit         |\n",
    "    |-----|---------------------------------------|--------------|\n",
    "    | 0   | apply -1 torque to the actuated joint | torque (N m) |\n",
    "    | 1   | apply 0 torque to the actuated joint  | torque (N m) |\n",
    "    | 2   | apply 1 torque to the actuated joint  | torque (N m) \n",
    "\n",
    "## Observation Space\n",
    "The observation is a ndarray with shape (6,) that provides information about the two rotational joint angles as well as their angular velocities.\n",
    "\n",
    "    | Num | Observation                  | Min                 | Max               |\n",
    "    |-----|------------------------------|---------------------|-------------------|\n",
    "    | 0   | Cosine of `theta1`           | -1                  | 1                 |\n",
    "    | 1   | Sine of `theta1`             | -1                  | 1                 |\n",
    "    | 2   | Cosine of `theta2`           | -1                  | 1                 |\n",
    "    | 3   | Sine of `theta2`             | -1                  | 1                 |\n",
    "    | 4   | Angular velocity of `theta1` | ~ -12.567 (-4 * pi) | ~ 12.567 (4 * pi) |\n",
    "    | 5   | Angular velocity of `theta2` | ~ -28.274 (-9 * pi) | ~ 28.274 (9 * pi) |\n",
    "\n",
    "where\n",
    "\n",
    "theta1 is the angle of the first joint, where an angle of 0 indicates the first link is pointing directly downwards.\n",
    "\n",
    "theta2 is relative to the angle of the first link. An angle of 0 corresponds to having the same angle between the two links.\n",
    "\n",
    "The angular velocities of theta1 and theta2 are bounded at ±4π, and ±9π rad/s respectively. A state of [1, 0, 1, 0, ..., ...] indicates that both links are pointing downwards.\n",
    "\n",
    "## Rewards\n",
    "The goal is to have the free end reach a designated target height in as few steps as possible, and as such all steps that do not reach the goal incur a reward of -1. Achieving the target height results in termination with a reward of 0. The reward threshold is -100.\n",
    "\n",
    "## Starting State\n",
    "Each parameter in the underlying state (theta1, theta2, and the two angular velocities) is initialized uniformly between -0.1 and 0.1. This means both links are pointing downwards with some initial stochasticity.\n",
    "\n",
    "## Episode End\n",
    "The episode ends if one of the following occurs:\n",
    "\n",
    "1. Termination: The free end reaches the target height, which is constructed as: -cos(theta1) - cos(theta2 + theta1) > 1.0\n",
    "\n",
    "2. Truncation: Episode length is greater than 500 (200 for v0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0bfbec0-e3b4-411c-be6b-b6909518baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Acrobot-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e8ca637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change the dynamics as described above\n",
    "env.env.book_or_nips = 'nips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c71c86c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "n_actions = env.action_space.n\n",
    "shape_states = env.observation_space.shape\n",
    "print(n_actions)\n",
    "print(shape_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da97111-5cc5-4420-979b-8557b88569cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state,theta): #softmax\n",
    "    p=state @ theta\n",
    "    return sc.special.softmax(p)\n",
    "\n",
    "def gradient_function(state,theta):\n",
    "    z=[0,0,0]\n",
    "    for i in range(3):\n",
    "        z[i]=np.dot(state,1-policy(state,theta)[i])\n",
    "    return np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3a7e71-32ba-4edf-9c0b-4f90eabba26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce(theta_0,lr,gamma,n_episode):\n",
    "    env = gym.make(\"Acrobot-v1\") #, render_mode=\"human\"\n",
    "    theta=theta_0\n",
    "    History=[]\n",
    "    \n",
    "    for i in range(n_episode):\n",
    "        X=[] #list of states\n",
    "        A=[] #list of actions\n",
    "        R=[] #list of rewards\n",
    "        x,_=env.reset()\n",
    "        n_move = 0 \n",
    "        terminated=False\n",
    "        truncated=False\n",
    "        while not terminated and not truncated: #episode to fill the lists\n",
    "            if n_move > 500:\n",
    "                env.close()\n",
    "                raise Exception(\"Too many attempts, failed\")\n",
    "            n_move += 1\n",
    "            X.append(x)\n",
    "            pol=policy(x, theta)\n",
    "            #print(pol)\n",
    "            action=np.random.choice([0,1,2], p=pol)\n",
    "            #print(action)\n",
    "            A.append(action)\n",
    "            x, r, terminated, truncated, info = env.step(action)\n",
    "            R.append(r)\n",
    "        \n",
    "        History.append(np.sum(R))\n",
    "        n=0 \n",
    "        while n<n_move: #list run for the adjustment of theta\n",
    "          \n",
    "            G=0\n",
    "            for i in range(n+1,n_move):\n",
    "                G=G+gamma**(i-n-1)*R[i]\n",
    "                \n",
    "            grad=np.transpose(gradient_function(X[n],theta))\n",
    "            theta=theta+lr*gamma**n*G*grad\n",
    "            \n",
    "            n += 1\n",
    "    #env.close()\n",
    "    return theta, History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "162261f0-f415-43c4-ac4a-e6a467844623",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "n_episode=100\n",
    "gamma=1\n",
    "U=np.random.uniform(0,1,18)\n",
    "theta_0=U.reshape((6,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96354f8b-92d3-4e9d-825e-7cb8e39f8c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-124.60012089, -274.94165851, -152.15847092],\n",
       "        [  29.83309144,    0.90688331,  -28.68907224],\n",
       "        [ -75.99381911, -174.50116268,  -98.05783915],\n",
       "        [  -1.71124265,    8.90064857,   11.26839414],\n",
       "        [ 213.87047419,  -70.77670543, -282.68658015],\n",
       "        [-433.91998441,   76.05018066,  511.99040072]]),\n",
       " [-148.0,\n",
       "  -65.0,\n",
       "  -92.0,\n",
       "  -124.0,\n",
       "  -65.0,\n",
       "  -82.0,\n",
       "  -64.0,\n",
       "  -93.0,\n",
       "  -74.0,\n",
       "  -70.0,\n",
       "  -72.0,\n",
       "  -87.0,\n",
       "  -89.0,\n",
       "  -89.0,\n",
       "  -86.0,\n",
       "  -66.0,\n",
       "  -64.0,\n",
       "  -66.0,\n",
       "  -81.0,\n",
       "  -74.0,\n",
       "  -90.0,\n",
       "  -149.0,\n",
       "  -65.0,\n",
       "  -100.0,\n",
       "  -90.0,\n",
       "  -73.0,\n",
       "  -89.0,\n",
       "  -74.0,\n",
       "  -87.0,\n",
       "  -79.0,\n",
       "  -182.0,\n",
       "  -74.0,\n",
       "  -89.0,\n",
       "  -88.0,\n",
       "  -73.0,\n",
       "  -65.0,\n",
       "  -78.0,\n",
       "  -73.0,\n",
       "  -64.0,\n",
       "  -79.0,\n",
       "  -208.0,\n",
       "  -74.0,\n",
       "  -177.0,\n",
       "  -88.0,\n",
       "  -64.0,\n",
       "  -66.0,\n",
       "  -92.0,\n",
       "  -90.0,\n",
       "  -72.0,\n",
       "  -90.0,\n",
       "  -87.0,\n",
       "  -73.0,\n",
       "  -90.0,\n",
       "  -65.0,\n",
       "  -76.0,\n",
       "  -72.0,\n",
       "  -66.0,\n",
       "  -93.0,\n",
       "  -76.0,\n",
       "  -109.0,\n",
       "  -87.0,\n",
       "  -73.0,\n",
       "  -105.0,\n",
       "  -64.0,\n",
       "  -64.0,\n",
       "  -74.0,\n",
       "  -64.0,\n",
       "  -74.0,\n",
       "  -89.0,\n",
       "  -75.0,\n",
       "  -72.0,\n",
       "  -66.0,\n",
       "  -85.0,\n",
       "  -74.0,\n",
       "  -65.0,\n",
       "  -73.0,\n",
       "  -74.0,\n",
       "  -92.0,\n",
       "  -78.0,\n",
       "  -90.0,\n",
       "  -72.0,\n",
       "  -73.0,\n",
       "  -90.0,\n",
       "  -167.0,\n",
       "  -84.0,\n",
       "  -101.0,\n",
       "  -64.0,\n",
       "  -87.0,\n",
       "  -72.0,\n",
       "  -85.0,\n",
       "  -81.0,\n",
       "  -90.0,\n",
       "  -135.0,\n",
       "  -78.0,\n",
       "  -66.0,\n",
       "  -73.0,\n",
       "  -105.0,\n",
       "  -72.0,\n",
       "  -90.0,\n",
       "  -73.0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reinforce(theta_0,lr,gamma,n_episode)\n",
    "#plt.plot(History)\n",
    "#plt.title(\"reward evolution\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469ed3a-bf9e-4b76-9e16-7f42f9740433",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
