{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d70632-9bb6-4b18-a9db-c410aa5fff51",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 2 : REINFORCE algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85378ca-f7e0-488f-af32-8b3cefbb4dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pygame\n",
    "from collections import deque\n",
    "from tqdm import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44da1d4f",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "The system consists of two links connected linearly to form a chain, with one end of the chain fixed. The joint between the two links is actuated. The goal is to apply torques on the actuated joint to swing the free end of the linear chain above a given height while starting from the initial state of hanging downwards.\n",
    "\n",
    "## Action Space\n",
    "The action is discrete, deterministic, and represents the torque applied on the actuated joint between the two links.\n",
    " | Num | Action                                | Unit         |\n",
    "    |-----|---------------------------------------|--------------|\n",
    "    | 0   | apply -1 torque to the actuated joint | torque (N m) |\n",
    "    | 1   | apply 0 torque to the actuated joint  | torque (N m) |\n",
    "    | 2   | apply 1 torque to the actuated joint  | torque (N m) \n",
    "\n",
    "## Observation Space\n",
    "The observation is a ndarray with shape (6,) that provides information about the two rotational joint angles as well as their angular velocities.\n",
    "\n",
    "    | Num | Observation                  | Min                 | Max               |\n",
    "    |-----|------------------------------|---------------------|-------------------|\n",
    "    | 0   | Cosine of `theta1`           | -1                  | 1                 |\n",
    "    | 1   | Sine of `theta1`             | -1                  | 1                 |\n",
    "    | 2   | Cosine of `theta2`           | -1                  | 1                 |\n",
    "    | 3   | Sine of `theta2`             | -1                  | 1                 |\n",
    "    | 4   | Angular velocity of `theta1` | ~ -12.567 (-4 * pi) | ~ 12.567 (4 * pi) |\n",
    "    | 5   | Angular velocity of `theta2` | ~ -28.274 (-9 * pi) | ~ 28.274 (9 * pi) |\n",
    "\n",
    "where\n",
    "\n",
    "theta1 is the angle of the first joint, where an angle of 0 indicates the first link is pointing directly downwards.\n",
    "\n",
    "theta2 is relative to the angle of the first link. An angle of 0 corresponds to having the same angle between the two links.\n",
    "\n",
    "The angular velocities of theta1 and theta2 are bounded at ±4π, and ±9π rad/s respectively. A state of [1, 0, 1, 0, ..., ...] indicates that both links are pointing downwards.\n",
    "\n",
    "## Rewards\n",
    "The goal is to have the free end reach a designated target height in as few steps as possible, and as such all steps that do not reach the goal incur a reward of -1. Achieving the target height results in termination with a reward of 0. The reward threshold is -100.\n",
    "\n",
    "## Starting State\n",
    "Each parameter in the underlying state (theta1, theta2, and the two angular velocities) is initialized uniformly between -0.1 and 0.1. This means both links are pointing downwards with some initial stochasticity.\n",
    "\n",
    "## Episode End\n",
    "The episode ends if one of the following occurs:\n",
    "\n",
    "1. Termination: The free end reaches the target height, which is constructed as: -cos(theta1) - cos(theta2 + theta1) > 1.0\n",
    "\n",
    "2. Truncation: Episode length is greater than 500 (200 for v0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0bfbec0-e3b4-411c-be6b-b6909518baf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of possible actions: Box(-2.0, 2.0, (1,), float32) that correspond to the torque applied to the free end of the pendulum (positive counter-clock wise)\n",
      "Number of states: Box([-1. -1. -8.], [1. 1. 8.], (3,), float32) that correspond to the x-y coordinates (Cartesian basis) and the angular velocity of the free end of the pendulum\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Acrobot-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ca637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change the dynamics as described above\n",
    "env.env.book_or_nips = 'nips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_actions = env.action_space.n\n",
    "shape_states = env.observation_space.shape\n",
    "print(n_actions)\n",
    "print(shape_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6da97111-5cc5-4420-979b-8557b88569cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_init(x):\n",
    "    theta=[0]*len(x)\n",
    "    return np.array(theta)\n",
    "\n",
    "def policy(action,state,theta):\n",
    "    p=state @ theta\n",
    "    q=1/(1+np.exp(-p))\n",
    "    if action==0:\n",
    "        return 1-q\n",
    "    else : \n",
    "        return q\n",
    "def gradient_function(action,state,theta):\n",
    "    if action==0:\n",
    "        return -state*policy(1,state,theta)\n",
    "    else :\n",
    "        return state*policy(0,state,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd89c547-c6ac-4b99-bd7e-d1aa69b677a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(state,theta):\n",
    "    if state[1]>=0:\n",
    "        action=np.random.uniform(-2,0)\n",
    "    else :\n",
    "        action=np.random.uniform(0,2)\n",
    "    return action\n",
    "\n",
    "def gradient_function(action,state,theta):\n",
    "    if action==0:\n",
    "        return -state*policy(1,state,theta)\n",
    "    else :\n",
    "        return state*policy(0,state,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff3a7e71-32ba-4edf-9c0b-4f90eabba26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce(theta_0,lr,gamma,n_episode):\n",
    "    env = gym.make(\"Pendulum-v1\", render_mode=\"human\")\n",
    "    theta=theta_0\n",
    "    \n",
    "    for i in range(n_episode):\n",
    "        X=[] #list of states\n",
    "        A=[] #list of actions\n",
    "        R=[] #list of rewards\n",
    "        x,_=env.reset()\n",
    "        n_move = 0 \n",
    "        terminated=False\n",
    "        while not terminated: #episode to fill the lists\n",
    "            if n_move > 500:\n",
    "                env.close()\n",
    "                raise Exception(\"Too many attempts, failed\")\n",
    "            n_move += 1\n",
    "            X.append(x)\n",
    "            \n",
    "            u= np.random.uniform(0,1)\n",
    "            if u<=policy(1,x,theta):\n",
    "                action=1\n",
    "            else :\n",
    "                action=0\n",
    "            A.append(action)\n",
    "            x, r, terminated, truncated, info = env.step([action])\n",
    "            R.append(r)\n",
    "        \n",
    "        print(\"Total rewards :\",np.sum(R))\n",
    "        n=0 \n",
    "        while n<n_move: #list run for the adjustment of theta\n",
    "          \n",
    "            G=0\n",
    "            for i in range(n+1,n_move):\n",
    "                G=G+gamma**(i-n-1)*R[i]\n",
    "                \n",
    "            grad=gradient_function(A[n],X[n],theta)\n",
    "            theta=theta+lr*gamma**n*G*grad\n",
    "            \n",
    "            n += 1\n",
    "    env.close()\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "162261f0-f415-43c4-ac4a-e6a467844623",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "n_episode=100\n",
    "gamma=1\n",
    "theta_0=[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96354f8b-92d3-4e9d-825e-7cb8e39f8c7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Too many attempts, failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3416\\3823776017.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mreinforce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta_0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_episode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3416\\3168402913.py\u001b[0m in \u001b[0;36mreinforce\u001b[1;34m(theta_0, lr, gamma, n_episode)\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_move\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Too many attempts, failed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mn_move\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Too many attempts, failed"
     ]
    }
   ],
   "source": [
    "reinforce(theta_0,lr,gamma,n_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452505c2-ec8a-452c-bbe3-b6ff8c01eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_episode):\n",
    "    env = gym.make(\"CartPole-v1\", render_mode = \"human\")\n",
    "    x,info=env.reset()\n",
    "    n_move=0\n",
    "    action = env.action_space.sample()\n",
    "    while not terminated:\n",
    "        if n_move > 10000:\n",
    "            raise Exception(\"Too many attempts, failed\")\n",
    "        n_move += 1\n",
    "        X.append(x)\n",
    "        policy=policyparam(action,x,theta)\n",
    "        action = np.argmax(policy)\n",
    "        A.append(action)\n",
    "        x, reward, terminated, truncated, info = env.step(action)\n",
    "        print(reward)\n",
    "        R.append(reward)\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
