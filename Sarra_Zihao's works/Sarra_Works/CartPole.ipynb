{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b9532f",
   "metadata": {},
   "source": [
    "<img src=\"CartPole.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870a3d3",
   "metadata": {},
   "source": [
    "We are going to try to learn a (parametrized) policy to win at the CartPole challenge using the REINFORCE algorithm. More specifically we use the following paramÃ©trization for $\\pi_\\theta$\n",
    "\\begin{equation*}\n",
    "\\mbox{logit} ~Pr(\\text{right} \\mid X = x) = x^\\top \\theta,\n",
    "\\end{equation*}\n",
    "where $x$ is the state vector and $\\theta$ a vector of parameters to be learnt. Note that we didn't not put an intercept in the above parametrization and it is intended."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ffd56",
   "metadata": {},
   "source": [
    "#### Question 1:\n",
    "\n",
    "Show that we have\n",
    "\\begin{equation*}\n",
    "  \\nabla \\log \\pi_\\theta(\\text{right} \\mid x) = x \\pi_\\theta(\\text{left} \\mid x)\n",
    "\\end{equation*}\n",
    " and\n",
    " \\begin{equation*}\n",
    "  \\nabla \\log \\pi_\\theta(\\text{left} \\mid x) = -x \\pi_\\theta(\\text{right} \\mid x).\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385b0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec42181",
   "metadata": {},
   "source": [
    "#### Question 2:\n",
    "\n",
    "Write a function that learns an optimal parametrized policy for the Cartpole challenge. Note that you may want to set the discount factor to $\\gamma = 1$ and the learning rate to $\\eta = 0.001$.\n",
    "\n",
    "*Hint: The **deque** object from **collections** might be useful to store efficiently an entire episode.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412c079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load reinforce.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdb146f",
   "metadata": {},
   "source": [
    "#### Question 3:\n",
    "\n",
    "Think about a $Q$--learning or SARSA learning strategies. What could be a drawback of such approaches for the cartpole problem? Does the REINFORCE strategy suffers from this limitation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7267222",
   "metadata": {},
   "source": [
    "#### Question 4:\n",
    "\n",
    "Run your brand new algorithm for say, $N = 1000$ episodes, and plot the evolution of the cumulative reward as the training goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "231c5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "## %load question_4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7020a562",
   "metadata": {},
   "source": [
    "#### Question 5:\n",
    "\n",
    "Based on your just learnt parametrized policy, play a game using this policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0c1ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load question_5.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
