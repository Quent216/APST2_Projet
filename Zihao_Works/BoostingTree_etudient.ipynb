{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commencons par ajuster un regresseur par gradient boosting sur des familles d'arbres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Préparation des données housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "california_housing = fetch_california_housing(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "An household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surpinsingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(california_housing.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california_housing.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n"
     ]
    }
   ],
   "source": [
    "X_housing = california_housing.data\n",
    "Y_housing = california_housing.target\n",
    "print(shape(X_housing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour éviter que les temps de calcul soient trop longs, nous allons travailler avec un sous échantillon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "X_housing, Y_housing  = resample(X_housing,Y_housing, n_samples = 2000, replace = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Découpage train / test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_housing_train, X_housing_test, y_housing_train, y_housing_test = \\\n",
    "train_test_split(X_housing,Y_housing,test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Fonctions Gradient Boosting de sckit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des fonctions Gradient Boosting de sckit-learn et de la fonction `mean_squared_error` pour le calcul des erreurs quadratique moyennes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ajustons maintenant un modèle GBM avec les paramètres proposés ci-dessous.\n",
    "\n",
    "> Retrouver la signification de chacun des paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(learning_rate=0.05, max_depth=8, min_samples_split=4,\n",
      "                          n_estimators=1000)\n"
     ]
    }
   ],
   "source": [
    "GBM = GradientBoostingRegressor(n_estimators=1000,\n",
    "                                         max_depth=8,\n",
    "                                         min_samples_split= 4,\n",
    "                                         learning_rate=0.05,\n",
    "                                         loss='squared_error')\n",
    "\n",
    "print(GBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ n_estimators : ###TO DO ### ?\n",
    "+ learning_rate =  ###TO DO ###?\n",
    "+ loss : ###TO DO ### ?\n",
    "+ max_depth : ###TO DO ### ?\n",
    "+ min_samples_split  : ###TO DO ### ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer l'erreur mse sur le test (aussi appelée deviance dans la doc) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43148229428060964\n"
     ]
    }
   ],
   "source": [
    "GBM.fit(X_housing_train, y_housing_train)\n",
    "mse = mean_squared_error(y_housing_test, GBM.predict(X_housing_test))\n",
    "print(mse) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention : le score renvoyé ci-dessous est un $R^2$ i.e. variance expliquée par le prédicteur / variance totale de $Y$, voir [ici](https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score-the-coefficient-of-determination)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7057234922353235\n"
     ]
    }
   ],
   "source": [
    "print(GBM.score(X_housing_test, y_housing_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques principes à retenir:\n",
    "+ Plus on ajuste d'arbres, plus le cout computationnel est élevé.\n",
    "+ le nombre d'arbres correspond au nombre d'itérations.\n",
    "+ Un taux d'apprentissage petit nécessitera plus d'arbres.\n",
    "+ Un taux d'apprentissage trop élevé fera des sauts de gradients potentiellement trop grands, et au bout d'un certain nombre d'itérations il sera  difficile d'améliorer les scores.\n",
    "+ Une bonne pratique consiste à choisir d'abord un taux d'apprentissage pas trop faible (pour ne pas faire exploser le nombre d'arbres) et à le diminuer ensuite, une fois ajustés les autres paramètres (nb de noeuds, profondeur ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etude des erreurs le long des itérations -  learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant étudier l'évolution de la perte en fonction du nombre d'itérations.\n",
    "\n",
    "Noter que l'erreur d'apprentissage est accessible dans GBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.26363570e+00 1.15563325e+00 1.05842182e+00 9.66761286e-01\n",
      " 8.84974386e-01 8.09833919e-01 7.42301941e-01 6.80328947e-01\n",
      " 6.23395964e-01 5.73334907e-01 5.26492728e-01 4.83667126e-01\n",
      " 4.44877882e-01 4.10427047e-01 3.78013710e-01 3.49096986e-01\n",
      " 3.22245165e-01 2.97696705e-01 2.75053240e-01 2.54768298e-01\n",
      " 2.35989845e-01 2.18725071e-01 2.03076573e-01 1.88631846e-01\n",
      " 1.75048867e-01 1.62348958e-01 1.50865863e-01 1.40449451e-01\n",
      " 1.30670180e-01 1.21879337e-01 1.13483749e-01 1.05820332e-01\n",
      " 9.87999778e-02 9.24155138e-02 8.66441657e-02 8.04808810e-02\n",
      " 7.53696841e-02 7.06572660e-02 6.65452757e-02 6.24161870e-02\n",
      " 5.88460380e-02 5.55354506e-02 5.23142580e-02 4.94841604e-02\n",
      " 4.68143975e-02 4.43412656e-02 4.21692063e-02 4.00336673e-02\n",
      " 3.81434862e-02 3.62662301e-02 3.45585267e-02 3.29244180e-02\n",
      " 3.10678409e-02 2.93687306e-02 2.81308271e-02 2.67268269e-02\n",
      " 2.55884127e-02 2.45587903e-02 2.31516179e-02 2.18970961e-02\n",
      " 2.07633525e-02 1.97934432e-02 1.89042856e-02 1.81958952e-02\n",
      " 1.73519049e-02 1.65405451e-02 1.58691718e-02 1.50726959e-02\n",
      " 1.45416841e-02 1.40274124e-02 1.35290545e-02 1.30835115e-02\n",
      " 1.26087824e-02 1.21993297e-02 1.18476489e-02 1.15594994e-02\n",
      " 1.12974439e-02 1.09708185e-02 1.06016932e-02 1.03622590e-02\n",
      " 1.00160054e-02 9.82435749e-03 9.58028653e-03 9.20005242e-03\n",
      " 8.87925243e-03 8.70830599e-03 8.42084708e-03 8.15658481e-03\n",
      " 7.85910151e-03 7.59487012e-03 7.39996349e-03 7.23589554e-03\n",
      " 7.01094884e-03 6.89232679e-03 6.71267945e-03 6.53162688e-03\n",
      " 6.42856267e-03 6.33749856e-03 6.25172730e-03 6.15182973e-03\n",
      " 6.06300190e-03 5.92628482e-03 5.80479475e-03 5.73257994e-03\n",
      " 5.66598426e-03 5.58973652e-03 5.53006764e-03 5.42448216e-03\n",
      " 5.34114302e-03 5.27382188e-03 5.21251474e-03 5.15859757e-03\n",
      " 5.00617647e-03 4.93020332e-03 4.84458641e-03 4.76607686e-03\n",
      " 4.69718366e-03 4.65666613e-03 4.59445202e-03 4.49291570e-03\n",
      " 4.45597611e-03 4.36656961e-03 4.29137014e-03 4.17976545e-03\n",
      " 4.12155505e-03 4.02007679e-03 3.97344359e-03 3.88122254e-03\n",
      " 3.84153295e-03 3.77017438e-03 3.74448279e-03 3.66362442e-03\n",
      " 3.61167115e-03 3.50829670e-03 3.45659267e-03 3.40010804e-03\n",
      " 3.30666286e-03 3.28743579e-03 3.23375754e-03 3.16043919e-03\n",
      " 3.13907754e-03 3.02299211e-03 2.96838705e-03 2.91259450e-03\n",
      " 2.87051472e-03 2.80168230e-03 2.75470556e-03 2.71248680e-03\n",
      " 2.69884918e-03 2.65916941e-03 2.53840418e-03 2.49709894e-03\n",
      " 2.47955211e-03 2.45737696e-03 2.40366581e-03 2.38802846e-03\n",
      " 2.34890934e-03 2.25261921e-03 2.19469862e-03 2.16351294e-03\n",
      " 2.09562125e-03 2.01900224e-03 2.00685926e-03 1.97676474e-03\n",
      " 1.94085405e-03 1.91188415e-03 1.88143421e-03 1.87194721e-03\n",
      " 1.85156902e-03 1.79615973e-03 1.78770842e-03 1.73358992e-03\n",
      " 1.68445012e-03 1.66446585e-03 1.61774645e-03 1.57852418e-03\n",
      " 1.56349233e-03 1.53082398e-03 1.50709290e-03 1.50030501e-03\n",
      " 1.48195161e-03 1.44619985e-03 1.42634163e-03 1.38981771e-03\n",
      " 1.35280542e-03 1.31587941e-03 1.28413204e-03 1.25736894e-03\n",
      " 1.23202989e-03 1.21319881e-03 1.20336897e-03 1.17992860e-03\n",
      " 1.16916792e-03 1.14193374e-03 1.12142813e-03 1.10871396e-03\n",
      " 1.09405926e-03 1.07571193e-03 1.06284732e-03 1.05559919e-03\n",
      " 1.03819686e-03 1.02680033e-03 1.01423066e-03 1.00100825e-03\n",
      " 9.91390834e-04 9.85537478e-04 9.71424404e-04 9.57161074e-04\n",
      " 9.37274179e-04 9.32960517e-04 9.16520701e-04 9.11258490e-04\n",
      " 9.05941689e-04 8.95838078e-04 8.74335256e-04 8.53199061e-04\n",
      " 8.45892966e-04 8.42618295e-04 8.28831579e-04 8.10510628e-04\n",
      " 7.90196402e-04 7.81698496e-04 7.66551095e-04 7.57401182e-04\n",
      " 7.49482096e-04 7.32438429e-04 7.28891688e-04 7.18302399e-04\n",
      " 7.01787010e-04 6.97852281e-04 6.89744321e-04 6.78201619e-04\n",
      " 6.58876419e-04 6.49032162e-04 6.38565790e-04 6.22183585e-04\n",
      " 6.12899083e-04 6.10762032e-04 5.96913754e-04 5.85926280e-04\n",
      " 5.72959134e-04 5.64989462e-04 5.52932935e-04 5.45419982e-04\n",
      " 5.42528710e-04 5.39211237e-04 5.25216491e-04 5.22764891e-04\n",
      " 5.11550606e-04 5.09748805e-04 4.97971709e-04 4.94766644e-04\n",
      " 4.83903537e-04 4.70512541e-04 4.62528941e-04 4.60284456e-04\n",
      " 4.48899492e-04 4.39139728e-04 4.35938652e-04 4.30109059e-04\n",
      " 4.21429676e-04 4.19675953e-04 4.16654921e-04 4.10001641e-04\n",
      " 4.05353282e-04 3.99503572e-04 3.93472498e-04 3.92044403e-04\n",
      " 3.84221007e-04 3.80945655e-04 3.72863489e-04 3.65636294e-04\n",
      " 3.63674442e-04 3.61350271e-04 3.56640784e-04 3.52446873e-04\n",
      " 3.42716587e-04 3.35782349e-04 3.32453806e-04 3.24603497e-04\n",
      " 3.20362709e-04 3.13144741e-04 3.09237357e-04 3.03232916e-04\n",
      " 2.94438520e-04 2.93020193e-04 2.88850080e-04 2.82389854e-04\n",
      " 2.76657324e-04 2.68920786e-04 2.66531675e-04 2.63300512e-04\n",
      " 2.60758954e-04 2.54913170e-04 2.49036844e-04 2.43912755e-04\n",
      " 2.41946842e-04 2.37249082e-04 2.31879544e-04 2.28946778e-04\n",
      " 2.25185568e-04 2.22060058e-04 2.20860210e-04 2.16790201e-04\n",
      " 2.13637048e-04 2.12925107e-04 2.08462200e-04 2.05551498e-04\n",
      " 2.03188744e-04 2.00794183e-04 1.95566453e-04 1.90620237e-04\n",
      " 1.88748121e-04 1.87902755e-04 1.82064275e-04 1.76726908e-04\n",
      " 1.75843466e-04 1.72749258e-04 1.72100823e-04 1.70852099e-04\n",
      " 1.65452826e-04 1.64009688e-04 1.62060397e-04 1.60875489e-04\n",
      " 1.59945040e-04 1.57769776e-04 1.55424803e-04 1.52402680e-04\n",
      " 1.51530376e-04 1.49301953e-04 1.46945992e-04 1.43516917e-04\n",
      " 1.41928316e-04 1.41060437e-04 1.37775128e-04 1.34808819e-04\n",
      " 1.32733286e-04 1.29982807e-04 1.28390424e-04 1.27490244e-04\n",
      " 1.24124958e-04 1.23483179e-04 1.22247998e-04 1.20754352e-04\n",
      " 1.18040095e-04 1.17480525e-04 1.15805385e-04 1.13515111e-04\n",
      " 1.12893802e-04 1.12641415e-04 1.11382684e-04 1.10426956e-04\n",
      " 1.08530856e-04 1.06180940e-04 1.03726641e-04 1.03135553e-04\n",
      " 1.00814012e-04 9.87217559e-05 9.62304660e-05 9.50651513e-05\n",
      " 9.40240817e-05 9.32476945e-05 9.26626045e-05 9.17619332e-05\n",
      " 9.08363584e-05 8.90322237e-05 8.86206862e-05 8.79710736e-05\n",
      " 8.69919965e-05 8.60058487e-05 8.45830032e-05 8.34603305e-05\n",
      " 8.09371419e-05 8.04981596e-05 7.98272731e-05 7.84713995e-05\n",
      " 7.76080587e-05 7.66851452e-05 7.62919900e-05 7.53964551e-05\n",
      " 7.45064420e-05 7.41663042e-05 7.39759143e-05 7.33483217e-05\n",
      " 7.28607459e-05 7.15671542e-05 7.12904839e-05 7.04741791e-05\n",
      " 6.96733797e-05 6.85946332e-05 6.74108434e-05 6.61336561e-05\n",
      " 6.57179098e-05 6.40092807e-05 6.37243159e-05 6.27480019e-05\n",
      " 6.22019379e-05 6.17739963e-05 6.08412364e-05 5.95352241e-05\n",
      " 5.88138705e-05 5.82160599e-05 5.67248330e-05 5.61087657e-05\n",
      " 5.58282268e-05 5.52234557e-05 5.41343837e-05 5.34081655e-05\n",
      " 5.23240661e-05 5.12257430e-05 5.04825061e-05 4.99552434e-05\n",
      " 4.96758019e-05 4.82518965e-05 4.71444350e-05 4.68786131e-05\n",
      " 4.63737528e-05 4.52012579e-05 4.39306011e-05 4.30508476e-05\n",
      " 4.23672529e-05 4.15321879e-05 4.07828025e-05 4.04249525e-05\n",
      " 3.96897305e-05 3.90923432e-05 3.84093602e-05 3.74267632e-05\n",
      " 3.71619922e-05 3.67344718e-05 3.63421959e-05 3.58879960e-05\n",
      " 3.55477600e-05 3.50340876e-05 3.44392743e-05 3.39866930e-05\n",
      " 3.35037930e-05 3.32252046e-05 3.27418394e-05 3.22764921e-05\n",
      " 3.18393495e-05 3.10517091e-05 3.04073366e-05 3.02547369e-05\n",
      " 3.00636862e-05 2.94028241e-05 2.83996729e-05 2.78125885e-05\n",
      " 2.76357285e-05 2.68486665e-05 2.61059921e-05 2.56479946e-05\n",
      " 2.53402053e-05 2.48378381e-05 2.39346100e-05 2.36428755e-05\n",
      " 2.35498369e-05 2.32822893e-05 2.31970997e-05 2.26512158e-05\n",
      " 2.24931432e-05 2.20025355e-05 2.18761362e-05 2.15505721e-05\n",
      " 2.11674598e-05 2.08326523e-05 2.04532970e-05 2.00458730e-05\n",
      " 1.97013660e-05 1.95068308e-05 1.88519511e-05 1.84702740e-05\n",
      " 1.83709703e-05 1.82882249e-05 1.82075397e-05 1.78643939e-05\n",
      " 1.77601097e-05 1.75695382e-05 1.73898298e-05 1.70361127e-05\n",
      " 1.69474421e-05 1.67354375e-05 1.63039491e-05 1.59349828e-05\n",
      " 1.57156660e-05 1.52940888e-05 1.49920736e-05 1.45463007e-05\n",
      " 1.44523933e-05 1.42028063e-05 1.41262155e-05 1.39915524e-05\n",
      " 1.37537533e-05 1.34295260e-05 1.31364980e-05 1.30304874e-05\n",
      " 1.26794189e-05 1.25946227e-05 1.23889205e-05 1.22007603e-05\n",
      " 1.20832074e-05 1.18902172e-05 1.17675772e-05 1.16813627e-05\n",
      " 1.15093425e-05 1.14673074e-05 1.11008306e-05 1.09069116e-05\n",
      " 1.08309220e-05 1.05014293e-05 1.03252983e-05 1.01016925e-05\n",
      " 1.00660060e-05 9.87835472e-06 9.59105457e-06 9.37866418e-06\n",
      " 9.06981414e-06 8.89200983e-06 8.61620597e-06 8.42594675e-06\n",
      " 8.21047401e-06 8.08388934e-06 8.02588576e-06 7.94327999e-06\n",
      " 7.91084818e-06 7.81507130e-06 7.73216354e-06 7.66429900e-06\n",
      " 7.62121257e-06 7.53353892e-06 7.46679164e-06 7.39627586e-06\n",
      " 7.34458904e-06 7.20736831e-06 7.14425759e-06 6.99670378e-06\n",
      " 6.81264807e-06 6.77080132e-06 6.65636291e-06 6.62141936e-06\n",
      " 6.59660841e-06 6.56087547e-06 6.47244302e-06 6.29412095e-06\n",
      " 6.26881193e-06 6.13448662e-06 6.05038116e-06 5.88590575e-06\n",
      " 5.79425392e-06 5.73336977e-06 5.62697528e-06 5.56323402e-06\n",
      " 5.53485870e-06 5.46493637e-06 5.30876722e-06 5.26879628e-06\n",
      " 5.25001736e-06 5.18316353e-06 5.13018171e-06 5.11232404e-06\n",
      " 5.08494753e-06 5.05635617e-06 4.94907673e-06 4.82361426e-06\n",
      " 4.75597621e-06 4.70461965e-06 4.67079190e-06 4.62333627e-06\n",
      " 4.59166245e-06 4.54296433e-06 4.49570912e-06 4.46462464e-06\n",
      " 4.38387987e-06 4.27843334e-06 4.22996934e-06 4.17667840e-06\n",
      " 4.08988467e-06 4.06105210e-06 3.98178778e-06 3.90060528e-06\n",
      " 3.86606275e-06 3.84097439e-06 3.78396826e-06 3.75290423e-06\n",
      " 3.71635103e-06 3.63155139e-06 3.56190366e-06 3.54656278e-06\n",
      " 3.50302874e-06 3.42822790e-06 3.35024865e-06 3.30571067e-06\n",
      " 3.24879347e-06 3.19701693e-06 3.17133615e-06 3.12475158e-06\n",
      " 3.08551860e-06 3.02315679e-06 2.98515789e-06 2.94873651e-06\n",
      " 2.89474587e-06 2.85147662e-06 2.82086687e-06 2.78388430e-06\n",
      " 2.68786468e-06 2.65331343e-06 2.59090206e-06 2.55744703e-06\n",
      " 2.54041850e-06 2.48142788e-06 2.45719037e-06 2.39186867e-06\n",
      " 2.35657324e-06 2.33226550e-06 2.27198170e-06 2.21098892e-06\n",
      " 2.12065007e-06 2.09996266e-06 2.07643157e-06 1.99645408e-06\n",
      " 1.92162296e-06 1.91026029e-06 1.86828477e-06 1.86269636e-06\n",
      " 1.83803357e-06 1.81770481e-06 1.81440156e-06 1.76912017e-06\n",
      " 1.73964766e-06 1.73454501e-06 1.70672670e-06 1.67199156e-06\n",
      " 1.66132157e-06 1.61075262e-06 1.58112930e-06 1.57432023e-06\n",
      " 1.53792809e-06 1.52626795e-06 1.50689252e-06 1.49332422e-06\n",
      " 1.48417818e-06 1.47895437e-06 1.44928651e-06 1.43662504e-06\n",
      " 1.42273340e-06 1.39531610e-06 1.38055703e-06 1.35606602e-06\n",
      " 1.33575179e-06 1.32314399e-06 1.30219649e-06 1.28556713e-06\n",
      " 1.24991188e-06 1.22364681e-06 1.21603136e-06 1.19622023e-06\n",
      " 1.17000320e-06 1.16273512e-06 1.15666585e-06 1.12645439e-06\n",
      " 1.11008873e-06 1.10651578e-06 1.09575597e-06 1.07231979e-06\n",
      " 1.05071725e-06 1.03801405e-06 1.01814005e-06 1.00369953e-06\n",
      " 9.89347499e-07 9.75368707e-07 9.45885245e-07 9.17179838e-07\n",
      " 8.95839716e-07 8.80070015e-07 8.61459669e-07 8.52067527e-07\n",
      " 8.44740272e-07 8.37143272e-07 8.25087354e-07 8.03955274e-07\n",
      " 8.01172826e-07 7.82913943e-07 7.62529185e-07 7.56810523e-07\n",
      " 7.43061565e-07 7.36289770e-07 7.22173255e-07 7.16872375e-07\n",
      " 7.05619523e-07 6.94456650e-07 6.80893987e-07 6.73264353e-07\n",
      " 6.68196073e-07 6.65309847e-07 6.49153300e-07 6.45794301e-07\n",
      " 6.40002728e-07 6.22469580e-07 6.10161653e-07 5.98540053e-07\n",
      " 5.84919643e-07 5.79613547e-07 5.78161505e-07 5.67632943e-07\n",
      " 5.61660924e-07 5.51209626e-07 5.47702625e-07 5.45621204e-07\n",
      " 5.27714078e-07 5.21469964e-07 5.18131197e-07 5.11791550e-07\n",
      " 5.09797485e-07 5.05913585e-07 4.99693037e-07 4.98093139e-07\n",
      " 4.92837935e-07 4.79500810e-07 4.76212436e-07 4.63790733e-07\n",
      " 4.62030583e-07 4.51319559e-07 4.46598293e-07 4.42012088e-07\n",
      " 4.29638403e-07 4.23910868e-07 4.18808581e-07 4.10511351e-07\n",
      " 3.98795446e-07 3.90719326e-07 3.81790428e-07 3.72283761e-07\n",
      " 3.63882487e-07 3.57340976e-07 3.54999705e-07 3.49491202e-07\n",
      " 3.43380539e-07 3.41022283e-07 3.37974940e-07 3.33255624e-07\n",
      " 3.23304285e-07 3.14326000e-07 3.13163764e-07 3.12355912e-07\n",
      " 3.10832824e-07 3.09789354e-07 3.04626225e-07 3.04162737e-07\n",
      " 3.01154039e-07 2.95900119e-07 2.91623936e-07 2.84898799e-07\n",
      " 2.80982724e-07 2.78400072e-07 2.73621429e-07 2.70789509e-07\n",
      " 2.64281640e-07 2.61413338e-07 2.58342906e-07 2.56070688e-07\n",
      " 2.52545598e-07 2.50261125e-07 2.47775355e-07 2.43814947e-07\n",
      " 2.42307673e-07 2.38307560e-07 2.33096384e-07 2.29908834e-07\n",
      " 2.28640996e-07 2.25371059e-07 2.23577255e-07 2.22766678e-07\n",
      " 2.19997346e-07 2.13365961e-07 2.12341407e-07 2.08881283e-07\n",
      " 2.03306220e-07 2.00134127e-07 1.97442444e-07 1.92870317e-07\n",
      " 1.90655100e-07 1.89523965e-07 1.87825812e-07 1.83043640e-07\n",
      " 1.80904867e-07 1.76484626e-07 1.75781342e-07 1.73448393e-07\n",
      " 1.67690246e-07 1.66384253e-07 1.65172983e-07 1.62855248e-07\n",
      " 1.57592864e-07 1.54988220e-07 1.52954751e-07 1.50580216e-07\n",
      " 1.48636184e-07 1.45271704e-07 1.44513090e-07 1.43788511e-07\n",
      " 1.40190423e-07 1.39324986e-07 1.38659317e-07 1.34858156e-07\n",
      " 1.31708836e-07 1.30141773e-07 1.27073965e-07 1.26459323e-07\n",
      " 1.23164164e-07 1.21440583e-07 1.19501660e-07 1.19004477e-07\n",
      " 1.16284233e-07 1.14736394e-07 1.12270734e-07 1.09611873e-07\n",
      " 1.08646085e-07 1.06117833e-07 1.05575984e-07 1.03918778e-07\n",
      " 1.02922156e-07 1.01746756e-07 1.01210016e-07 9.78165614e-08\n",
      " 9.62484223e-08 9.57741053e-08 9.50637436e-08 9.29721819e-08\n",
      " 9.21032194e-08 9.17666461e-08 9.05317404e-08 8.86873754e-08\n",
      " 8.81250451e-08 8.61819052e-08 8.38564528e-08 8.22920430e-08\n",
      " 8.05712656e-08 7.85303502e-08 7.75832014e-08 7.63699934e-08\n",
      " 7.45289966e-08 7.39236867e-08 7.22729108e-08 7.19213874e-08\n",
      " 7.15216346e-08 7.01716583e-08 6.96916444e-08 6.95674185e-08\n",
      " 6.86306541e-08 6.74629723e-08 6.71151438e-08 6.67417004e-08\n",
      " 6.57933163e-08 6.41807858e-08 6.37428514e-08 6.32359168e-08\n",
      " 6.28635888e-08 6.16885172e-08 6.05633717e-08 5.98394370e-08\n",
      " 5.90473088e-08 5.81856001e-08 5.75649292e-08 5.69810671e-08\n",
      " 5.64020796e-08 5.58602511e-08 5.51220626e-08 5.45101632e-08\n",
      " 5.38540845e-08 5.32267611e-08 5.26351263e-08 5.08705752e-08\n",
      " 5.06725914e-08 5.02161254e-08 5.00109620e-08 4.88999255e-08\n",
      " 4.81240912e-08 4.75528939e-08 4.73492366e-08 4.64335420e-08\n",
      " 4.62270803e-08 4.60402436e-08 4.56089230e-08 4.54957803e-08\n",
      " 4.47941724e-08 4.45232088e-08 4.41038096e-08 4.37603744e-08\n",
      " 4.29883651e-08 4.23808513e-08 4.17781350e-08 4.14149314e-08\n",
      " 4.10954483e-08 3.97055674e-08 3.92003001e-08 3.91021112e-08\n",
      " 3.89130733e-08 3.86321512e-08 3.77038113e-08 3.71260043e-08\n",
      " 3.69756821e-08 3.65545967e-08 3.59160196e-08 3.55862716e-08\n",
      " 3.51408458e-08 3.46866470e-08 3.43467149e-08 3.35932606e-08\n",
      " 3.27356813e-08 3.21461702e-08 3.16204185e-08 3.10923883e-08\n",
      " 3.09679321e-08 3.02241875e-08 3.01120938e-08 2.94343949e-08\n",
      " 2.87743946e-08 2.85958176e-08 2.78490454e-08 2.77300744e-08\n",
      " 2.68931544e-08 2.67162572e-08 2.66106397e-08 2.61794559e-08\n",
      " 2.54773524e-08 2.53005038e-08 2.49704357e-08 2.47572759e-08\n",
      " 2.46275493e-08 2.45310279e-08 2.40777967e-08 2.36997708e-08\n",
      " 2.36421027e-08 2.35331681e-08 2.32126216e-08 2.30437092e-08\n",
      " 2.27249843e-08 2.25965742e-08 2.25230947e-08 2.23703333e-08\n",
      " 2.21957275e-08 2.20978224e-08 2.20300528e-08 2.17159759e-08\n",
      " 2.14684926e-08 2.09146198e-08 2.05815454e-08 2.05435912e-08\n",
      " 2.04685804e-08 2.02108501e-08 1.98980575e-08 1.96640083e-08\n",
      " 1.94987207e-08 1.94228051e-08 1.92013452e-08 1.87271559e-08\n",
      " 1.86638793e-08 1.84498089e-08 1.81349507e-08 1.77783550e-08\n",
      " 1.76402955e-08 1.72584878e-08 1.71924551e-08 1.70917318e-08\n",
      " 1.69064897e-08 1.68287128e-08 1.67625519e-08 1.65786497e-08\n",
      " 1.60792200e-08 1.60011995e-08 1.59141132e-08 1.58559728e-08\n",
      " 1.57981246e-08 1.56813447e-08 1.55369562e-08 1.54536142e-08\n",
      " 1.52603114e-08 1.51195316e-08 1.50535611e-08 1.49721401e-08\n",
      " 1.48586258e-08 1.46096352e-08 1.42205746e-08 1.41072392e-08\n",
      " 1.39570245e-08 1.39243026e-08 1.37115079e-08 1.36529779e-08\n",
      " 1.35133978e-08 1.34702011e-08 1.34175079e-08 1.32642614e-08\n",
      " 1.31167604e-08 1.30089183e-08 1.28061555e-08 1.27199546e-08\n",
      " 1.26618338e-08 1.25060155e-08 1.24302509e-08 1.22632252e-08]\n"
     ]
    }
   ],
   "source": [
    "print(GBM.train_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons aussi tracer l'évolution de l'erreur de test mse (ou bien le score $R^2$) le long des itérations. En effet, pour retrouver tous les estimateurs temporaires à chaque de l'étape de l'algo, il suffit de considérer la somme tronquée du prédicteur boosting final. \n",
    "> Utiliser les méthodes `staged_predict()` et `loss_()` de la classe `GradientBoostingRegressor` pour afficher l'erreur de test en fonction du nombre d'itérations. Comparer avec l'erreur sur le train. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = []\n",
    "for y_pred in  GBM.staged_predict(X_housing_test):\n",
    "    test_score.append(GBM.loss_(y_pred, y_housing_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(GBM.n_estimators) + 1, GBM.train_score_, 'b-',\n",
    "         label='Training mse')\n",
    "plt.plot(np.arange(GBM.n_estimators) + 1, test_score, 'r-',\n",
    "         label='Test mse')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Boosting Iterations')\n",
    "plt.ylabel('mse');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Est-il ici pertinent de faire du \"early stopping\" i.e. considérer une somme tronquée du prédicteur boosting pour contrôler le sur-apprentissage ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO ###\n",
    "Ce n'est pas nécessaire, car nous pouvons voir que l'erreur n'augmente pas après quelques itérations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Superposer quelques trajectoires pour plusieurs valeurs du learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO ###\n",
    "GBM_lr = []\n",
    "lr_list = [0.05, 0.1, 0.15, 0.2]\n",
    "for i, lr in enumerate(lr_list):\n",
    "    GBM_lr.append(GradientBoostingRegressor(n_estimators = 1000,\n",
    "                                    max_depth = 8,\n",
    "                                    min_samples_split = 4,\n",
    "                                    learning_rate = lr,\n",
    "                                    loss = 'squared_error'))\n",
    "    GBM_lr[i].fit(X_housing_train, y_housing_train)\n",
    "    test_score = []\n",
    "    for y_pred in  GBM_lr[i].staged_predict(X_housing_test):\n",
    "        test_score.append(GBM_lr[i].loss_(y_pred, y_housing_test))\n",
    "    # dessin\n",
    "    plt.plot(np.arange(GBM_lr[i].n_estimators) + 1, GBM.train_score_, 'b-',\n",
    "             label='Training mse'+' '+str(i+1))\n",
    "    plt.plot(np.arange(GBM_lr[i].n_estimators) + 1, test_score, 'r-',\n",
    "             label='Test mse'+' '+str(i+1))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Boosting Iterations')\n",
    "    plt.ylabel('mse');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix des paramètres du GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Pour `n_estimators=300` et `learning_rate=0.1`, effectuer une recherche avec par `GridSearch()` pour choisir `max_depth` et  `min_samples_split`. Faire cette recherche en \"cross validant\" uniquement l'échantillon d'apprentissage de façon à garder des données pour évaluer les performances du modèle finalement sélectionné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_values= [2,4,6,8] \n",
    "min_samples_split_values= [2,3,4]\n",
    "\n",
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "GBM = ### TODO ###\n",
    "param_grid = dict(m### TODO ###)\n",
    "grid_search = GridSearchCV(### TODO ###)\n",
    "grid_result = grid_search.fit(### TODO ###)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Une fois ces valeurs choisies, diminuer le learning rate et augmenter le nombre d'itérations pour essayer d'améliorer encore les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Calculer le $R^2$ et l'erreur de test pour le modèle final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_estimator_.score(### TODO ###)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(### TODO ###)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indices d'importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Il est aussi possible de calculer des indices d'importances pour les GMB avec la méthode `feature_importances_`. Comparer les importances du modèle GMB obtenu avec celles obtenues précédemment pour les forêts aléatoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBMbest = grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On commence ajuster le modele choisi sur toutes les données:\n",
    "GBMbest.fit(X_housing,Y_housing);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = GBMbest.feature_importances_\n",
    "### TODO : affichage ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nécessaire, installer la librairie [`xgboost`](https://xgboost.readthedocs.io/en/latest/install.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utilser Xgboost avec pour classifieurs faibles des arbres (on pourait aussi utiliser aussi des modèles linéaires basés sur peu de variabes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres de Xgboost, notamment pour les fonctions `XGBRegressor()` et `XGBClassifier()`, sont décrits dans [cette page](http://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn). Elles sont similaires aux commdandes des fonctions de sckit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBR = XGBRegressor()\n",
    "XGBR.fit(X_housing_train, y_housing_train)\n",
    "y_pred = XGBR.predict(X_housing_test)\n",
    "XGBR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Donner le score $R^2$ et l'erreur mse. Comparer avec GBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les remarques précedentes sur les reglages des paramètres de GBM sont encore vraies pour Xgboost. Il faut en plus ajuster les paramètres `alpha`  et `lambda` des termes de régularisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Choisir les paramètres de Xgboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'abord avec un learning rate pas trop faible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth= [2,4,6,8] \n",
    "min_child_weight = [2,4]\n",
    "reg_alpha=  [0,0.1,1,2]\n",
    "reg_lambda = [0,0.1,1,2]\n",
    "### TODO ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et maintenant avec des learning rates plus petits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.001, 0.01,0.05]\n",
    "n_estimators = [100,500,1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### TODO : Graphe de la mse ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation du Boosting Regressor \n",
    "\n",
    "> Implémenter votre propore fonction Tree Boosting Regressor, on considérant la perte $\\ell_2$. On pourra pour cela, à chaque itération, \n",
    "ajuster un arbre de régression (de faible prodondeur) sur les résidus courants, à l'aide de la fonction `tree.DecisionTreeRegressor()` . L'étape 5 de l'Algorithme 6 \"Gradient Tree Boosting Regressor Algorithm\" donné en cours est-elle nécessaire dans ce contexte ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
